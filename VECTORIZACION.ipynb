{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ae8e05",
   "metadata": {},
   "source": [
    "# Optimización con Vectorización en Python\n",
    "En este notebook exploraremos cómo aprovechar la vectorización en Python usando NumPy y PyTorch, así como los conceptos clave de SIMD, BLAS y la optimización de inferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31afff51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## Conceptos Clave de Vectorización y Eficiencia Computacional\n",
    "\n",
    "La vectorización no solo simplifica el código, sino que proporciona **mejoras sustanciales en rendimiento** al aprovechar:\n",
    "- **Instrucciones SIMD**: Modernas CPUs incluyen extensiones (SSE, AVX, NEON) que ejecutan la misma operación sobre múltiples datos en un solo ciclo, procesando en paralelo vectores de 4, 8 o más valores.\n",
    "- **Operaciones en C optimizado**: Las funciones universales de NumPy (ufuncs) están escritas en C, evitando el overhead del intérprete Python en cada iteración.\n",
    "- **Localidad de memoria**: Al trabajar con arrays contiguos, se maximizan los “cache hits” de L1/L2/L3, reduciendo dramáticamente los accesos a memoria RAM.\n",
    "- **BLAS/MKL/OpenBLAS multihilo**: Para álgebra lineal pesada (`np.dot`, `np.linalg.inv`, multiplicaciones matriciales), estas bibliotecas distribuyen el cómputo entre varios núcleos, equilibrando carga y minimizando tiempos de espera.\n",
    "- **Broadcasting**: Permite operar sin crear copias innecesarias de arrays, reusando la misma memoria y evitando loops Python implícitos.\n",
    "- **Menos GIL**: Al delegar todo el trabajo en C (o en GPU para PyTorch/TensorFlow), se liberan cuellos de botella asociados al Global Interpreter Lock de Python.\n",
    "- **GPU y Tensor Cores**: En Deep Learning, frameworks vectorizados extienden estos principios al hardware de GPU, usando miles de núcleos paralelos y Tensor Cores para acelerar multiplicaciones de matrices a precisión reducida (FP16/TF32).\n",
    "\n",
    "> **Reflexión**: Al vectorizar, transformas tu código de una serie de bucles Python en una composición de operaciones de alto nivel ejecutadas directamente en hardware especializado, logrando **ganancias de 10× a 100×** en muchas tareas numéricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ddf7c3",
   "metadata": {},
   "source": [
    "\n",
    "## Detalle del Pipeline de Optimización\n",
    "\n",
    "1. **Identificación de cuellos de botella**: Usa `%timeit`, `cProfile` o `line_profiler` para detectar loops costosos.\n",
    "2. **Reemplazo por ufuncs**: Sustituye cada iteración por llamadas a `np.add`, `np.multiply`, `np.dot`, etc.\n",
    "3. **Validación de shapes**: Al usar broadcasting, verifica que las dimensiones sean compatibles para evitar bugs silenciosos.\n",
    "4. **Ajuste de dtype**: Selecciona tipos de datos más ligeros (`float32` vs `float64`) para reducir carga de memoria y acelerar cálculos.\n",
    "5. **Test de rendimiento**: Mide antes y después de cada cambio para asegurar que la vectorización aporta mejoras reales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c2f3c",
   "metadata": {},
   "source": [
    "## Implementación del Código Completo\n",
    "A continuación presentamos el código con docstrings y comentarios explicativos, demostrando generación de datos, entrenamiento y una inferencia vectorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def generar_datos_sinteticos(num_muestras=5000):\n",
    "    \"\"\"\n",
    "    Genera un conjunto de datos sintético para clasificación binaria.\n",
    "    Cada muestra es un vector de 10 características muestreado de una distribución\n",
    "    normal estándar. La etiqueta es 1 si la suma de las características es positiva,\n",
    "    y 0 en caso contrario.\n",
    "\n",
    "    Args:\n",
    "        num_muestras (int): Número de ejemplos a generar.\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): Matriz de características de forma (num_muestras, 10).\n",
    "        y (np.ndarray): Vector de etiquetas binarias de longitud num_muestras.\n",
    "    \"\"\"\n",
    "    X = np.random.randn(num_muestras, 10)\n",
    "    y = (np.sum(X, axis=1) > 0).astype(int)\n",
    "    return X, y\n",
    "\n",
    "class RedNeuronalSimple(nn.Module):\n",
    "    \"\"\"\n",
    "    Una red neuronal de dos capas para clasificación binaria.\n",
    "    Arquitectura: Linear -> ReLU -> Linear.\n",
    "\n",
    "    Args:\n",
    "        dim_entrada (int): Características de entrada.\n",
    "        dim_oculta (int): Neuronas capa oculta.\n",
    "        dim_salida (int): Clases de salida.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_entrada=10, dim_oculta=32, dim_salida=2):\n",
    "        super().__init__()\n",
    "        self.modelo = nn.Sequential(\n",
    "            nn.Linear(dim_entrada, dim_oculta),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_oculta, dim_salida)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.modelo(x)\n",
    "\n",
    "def entrenar_modelo(modelo, X_train, y_train, epochs=5, batch_size=128):\n",
    "    \"\"\"\n",
    "    Entrena el modelo con Adam y CrossEntropyLoss. Usa DataLoader con num_workers=2.\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(modelo.parameters(), lr=1e-3)\n",
    "    criterio = nn.CrossEntropyLoss()\n",
    "    modelo.train()\n",
    "\n",
    "    tensor_X = torch.tensor(X_train, dtype=torch.float32)\n",
    "    tensor_y = torch.tensor(y_train, dtype=torch.long)\n",
    "    dataset = torch.utils.data.TensorDataset(tensor_X, tensor_y)\n",
    "    loader  = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        perdida_acum = 0.0\n",
    "        for bx, by in loader:\n",
    "            optimizer.zero_grad()\n",
    "            salidas = modelo(bx)\n",
    "            loss = criterio(salidas, by)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            perdida_acum += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Pérdida Promedio: {perdida_acum/len(loader):.4f}\")\n",
    "\n",
    "def inferencia_vectorizada(modelo, X_data, batch_size=None, device='cpu'):\n",
    "    \"\"\"\n",
    "    Realiza inferencia vectorizada: procesa todo el batch en C/CUDA.\n",
    "    Args:\n",
    "        modelo (nn.Module): Red entrenada.\n",
    "        X_data (np.ndarray): Datos de prueba.\n",
    "        batch_size (int|None): Divide en batches si es necesario.\n",
    "        device (str): 'cpu' o 'cuda'.\n",
    "    Returns:\n",
    "        np.ndarray: Predicciones.\n",
    "    \"\"\"\n",
    "    modelo.to(device).eval()\n",
    "    with torch.no_grad():\n",
    "        tensor_X = torch.tensor(X_data, dtype=torch.float32, device=device)\n",
    "        if batch_size:\n",
    "            preds = []\n",
    "            for i in range(0, len(tensor_X), batch_size):\n",
    "                batch = tensor_X[i:i+batch_size]\n",
    "                out = modelo(batch)\n",
    "                preds.append(out.argmax(dim=1).cpu())\n",
    "            return torch.cat(preds).numpy()\n",
    "        else:\n",
    "            out = modelo(tensor_X)\n",
    "            return out.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    1. Genera datos.\n",
    "    2. Divide en entrenamiento/test.\n",
    "    3. Entrena red.\n",
    "    4. Infere vectorizado.\n",
    "    5. Mide tiempos y precisión.\n",
    "    \"\"\"\n",
    "    X, y = generar_datos_sinteticos(5000)\n",
    "    split = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:split], X[split:]\n",
    "    y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "    modelo = RedNeuronalSimple()\n",
    "\n",
    "    print(\"Entrenando...\")\n",
    "    t0 = time.time()\n",
    "    entrenar_modelo(modelo, X_train, y_train, epochs=5, batch_size=128)\n",
    "    print(f\"→ Entrenamiento en {time.time() - t0:.2f}s\\n\")\n",
    "\n",
    "    print(\"Inferencia vectorizada...\")\n",
    "    t1 = time.time()\n",
    "    pred = inferencia_vectorizada(modelo, X_test)\n",
    "    print(f\"→ Inferencia en {time.time() - t1:.2f}s\")\n",
    "\n",
    "    precision = (pred == y_test).mean() * 100\n",
    "    print(f\"Precisión en Test: {precision:.2f}%\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
